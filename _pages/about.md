---
permalink: /
title: "üëãAbout Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


I am a third-year Master's student in Data Science at Tsinghua University, advised by Prof. [Shao-Lun Huang](https://sites.google.com/view/slhuang/home). Before that, I earned my B.S. in Electronic Engineering from Sun Yat-sen University (SYSU) in 2022, under the guidance of Prof. [Yulan Guo](http://www.yulanguo.cn/). Currently I'm a research intern at Microsoft Research Asia, working with Dr. [Yeyun Gong](https://www.microsoft.com/en-us/research/people/yegong/). I also interned at Tencent AI Lab, collaborating with Dr. [Pengyu Cheng](https://linear95.github.io/). 

My current research focuses on pre-training strategy and reinforcement learning (RL) for Large Language Models (LLMs), with a long-term aim at AGI. 
I am excited to apply for Fall 2025 PhD programs and investigate potential collaborations. If you are interested in discussing opportunities or have any questions, please feel free to [EMAIL](mailto:vitoliang0601@gmail.com) me. I genuinely appreciate your consideration and look forward to connecting with you.

  

üìñEducation
======
- **Aug. 2022 - Jun. 2025 (Expected)** M.Sc., Data Science and Information Technology, Tsinghua University, Beijing, China.
<br>*GPA: 3.98/4.0, Top 3%*

- **Sep. 2018 - Jun. 2022** B.Sc., Electronic Information Science and Technology, Sun Yat-sen University, Guangzhou, China.
<br>*GPA: 4.11/5.0, Top 3%*

  

üìëPublications
======
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;" border="1" cellspacing="0" cellpadding="10"><tbody>	

  <!--Entity Sum-->
  <tr>
    <td style="padding:20px;width:30%;max-width:30%" align="center">
      <img style="width:100%;max-width:100%" src="../images/Entity_sum.png" alt="dise">
    </td>
    <td width="75%" valign="center">
      <papertitle>What You See Is What You Get: Entity-Aware Summarization for Reliable Sponsored Search</papertitle>
      <br>
      <b>Xiao Liang</b>, Xinyu Hu, Simiao Zuo, Jimi He, Yu Wang, Victor Ye Dong, Yeyun Gong, Kushal S. Dave, Yi Liu, Qiang Lou, Shao-Lun Huang, Jian Jiao
      <br>
      <em>NeurIPS 2024 SafeGenAi, </em> <a href="https://github.com/MasterVito/MasterVito.github.io/raw/master/_publications/NIPS_WS_2024_Entity_Sum_CR.pdf">[PDF]</a>
      <br>
      <p> We introduce a framework for generating reliable AI-driven entity-aware summaries for information retrieval in the sponsored search ads domain.</p>
    </td>
  </tr>	


  <!--Integrative Decoding-->
  <tr>
    <td style="padding:20px;width:30%;max-width:30%" align="center">
      <img style="width:100%;max-width:100%" src="../images/Int_decode.png" alt="dise">
    </td>
    <td width="75%" valign="center">
      <papertitle>Integrative Decoding: Improve Factuality via Implicit Self-consistency</papertitle>
      <br>
      Yi Cheng, <b>Xiao Liang</b>, Yeyun Gong, Wen Xiao, Song Wang, Yuji Zhang, Wenjun Hou, Kaishuai Xu, Wenge Liu, Wenjie Li, Jian Jiao, Qi Chen, Peng Cheng, Wayne Xiong
      <br>
      <em> Preprint 2024, </em> <a href="https://arxiv.org/abs/2410.01556">[PDF]</a>
      <br>
      <p> This paper presents a self-consistency based decoding strategy for improving the factual accuracy of large language models, especially in long-form generation tasks.</p>
    </td>
  </tr>	


  <!--TRAIT-->
  <tr>
    <td style="padding:20px;width:30%;max-width:30%" align="center">
      <img style="width:100%;max-width:100%" src="../images/TRAIT.png" alt="dise">
    </td>
    <td width="75%" valign="center">
      <papertitle>Task Oriented In-Domain Data Augmentation</papertitle>
      <br>
      <b>Xiao Liang*</b> , Xinyu Hu*, Simiao Zuo, Yeyun Gong, Qiang Lou, Yi Liu, Shao-Lun Huang, Jian Jiao
      <br>
      <em>EMNLP 2024, </em> <a href="https://arxiv.org/pdf/2406.16694">[PDF]</a>
      <br>
      <p> We propose a task-oriented in-domain data augmentation framework consisting of in-domain data selection and task-oriented synthetic passage generation.</p>
    </td>
  </tr>	


  <!--DiffusionVG-->
  <tr>
    <td style="padding:20px;width:30%;max-width:30%" align="center">
      <img style="width:100%;max-width:100%" src="../images/diffusionvg.png" alt="dise">
    </td>
    <td width="75%" valign="center">
      <papertitle>Exploring Iterative Refinement with Diffusion Models for Video Grounding</papertitle>
      <br>
      <b>Xiao Liang*</b>, Tao Shi*, Yaoyuan Liang, Te Tao, Shao-Lun Huang
      <br>
      <em>ICME 2024, </em> <a href="https://arxiv.org/pdf/2310.17189">[PDF]</a> <a href="https://github.com/MasterVito/DiffusionVG">[Code]</a> 
      <br>
      <p> We propose a novel framework with diffusion models that formulates video grounding as a conditioned generation task, enhancing predictions through iterative refinement.</p>
    </td>
  </tr>	

  <!--CoSTA-->
  <tr>
    <td style="padding:20px;width:30%;max-width:30%" align="center">
      <img style="width:100%;max-width:100%" src="../images/costa.png" alt="dise">
    </td>
    <td width="75%" valign="center">
      <papertitle>CoSTA: End-to-End Comprehensive Space-Time Entanglement for Spatio-Temporal Video Grounding</papertitle>
      <br>
      Yaoyuan Liang*, <b>Xiao Liang*</b>, Yansong Tang, Zhao Yang, Ziran Li, Jingang Wang, Wenbo Ding, Shao-Lun Huang
      <br>
      <em>AAAI 2024, </em> <a href="https://ojs.aaai.org/index.php/AAAI/article/download/28118/28240">[PDF]</a>
      <br>
      <p> We propose a framework of Comprehensive Space-Time entAnglement to densely entangle space-time multi-modal features for spatio-temporal localization.</p>
    </td>
  </tr>	


  <!--SSLCL-->
  <tr>
    <td style="padding:20px;width:30%;max-width:30%" align="center">
      <img style="width:100%;max-width:100%" src="../images/sslcl.png" alt="dise">
    </td>
    <td width="75%" valign="center">
      <papertitle>SSLCL: An Efficient Model-Agnostic Supervised Contrastive Learning Framework for Emotion Recognition in Conversations</papertitle>
      <br>
      Tao Shi*, <b>Xiao Liang*</b>, Yaoyuan Liang, Xinyi Tong, Shao-Lun Huang
      <br>
      <em>Preprint 2023, </em> <a href="https://arxiv.org/pdf/2310.16676">[PDF]</a> <a href="https://github.com/TaoShi1998/SSLCL">[Code]</a> 
      <br>
      <p> We introduce utilizing label representations by projecting discrete labels into dense embeddings for multimodal emotion classification.</p>
    </td>
  </tr>	

  <!--SimCAS-->
  <tr>
    <td style="padding:20px;width:30%;max-width:30%" align="center">
      <img style="width:100%;max-width:100%" src="../images/simcas.png" alt="dise">
    </td>
    <td width="75%" valign="center">
      <papertitle>Chunk, Align, Select: A Simple Long-sequence Processing Method for Transformers</papertitle>
      <br>
      Jiawen Xie, Pengyu Cheng, <b>Xiao Liang</b>, Yong Dai, Nan Du
      <br>
      <em>ACL 2024, </em> <a href="https://arxiv.org/pdf/2308.13191">[PDF]</a> <a href="https://github.com/xjw-nlp/SimCAS">[Code]</a> 
      <br>
      <p> We propose a token selection framework for pre-trained transformers to process long sequences utilizing reinforcement learning.</p>
    </td>
  </tr>

  <!--unleash-then-eliminate-->
  <tr>
    <td style="padding:20px;width:30%;max-width:30%" align="center">
      <img style="width:100%;max-width:100%" src="../images/unleash-then-eliminate.png" alt="dise">
    </td>
    <td width="75%" valign="center">
      <papertitle>Unleash Region Understanding in Intermediate Layers for MLLM-based Referring Expression Generation </papertitle>
      <br>
      Yaoyuan Liang, Zhuojun Cai, Jian Xu, Guanbo Huang, Yiran Wang, <b>Xiao Liang</b>, Jiahao Liu, Ziran Li, Jingang Wang, Shao-Lun Huang
      <br>
      <em>NeurIPS 2024, </em> [To be present]
      <br>
      <p> We present to elicit the latent information in intermediate layers adopt a cycle-consistency-based decoding method to alleviate hallucinations in the REG task. </p>
    </td>
  </tr>


</tbody></table>
(* indicates equal contribution)


üßë‚ÄçüíªExperience
======
- (Nov. 2023 - Present) Reserch Intern, NLC Group, Microsoft Research Asia, Beijing, China.
<br> Mentor: [Yeyun Gong](https://www.microsoft.com/en-us/research/people/yegong/)
<br> Working on large language models, pre-training strategy and model architecture.

- (Mar. 2023 - Sep. 2023) Research Intern, AI Lab, Tencent Inc., Guangdong, China.
<br> Mentor: [Pengyu Cheng](https://linear95.github.io/), [Nan Du](https://scholar.google.com/citations?hl=en&user=BO4jEkAAAAAJ)
<br> Working on large language models, long sequence processing.


üèÜHonors and Awards
======
- Outstanding Graduate Thesis, Sun Yat-sen University, Guangdong, 2022
- Outstanding Graduate Student, Sun Yat-sen University, Guangdong, 2022
- Second Prize Scholarship, Sun Yat-sen University, Guangdong, 2019~2022
- 1st of the 2022 Tsinghua Open Hack Competition - Multimodal Learning Track, Tsinghua University, Beijing, 2022